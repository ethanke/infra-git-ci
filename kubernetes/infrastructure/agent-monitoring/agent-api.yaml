# Agent-Ready Monitoring Configuration
# Provides API endpoints and webhooks for AI agent integration

apiVersion: v1
kind: Namespace
metadata:
  name: agent-monitoring
  labels:
    app.kubernetes.io/part-of: lum-gitops
    lum.tools/component: agent-monitoring
---
# ConfigMap for agent monitoring configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: agent-monitoring-config
  namespace: agent-monitoring
data:
  config.yaml: |
    # Agent API Configuration
    api:
      enabled: true
      port: 8080
      auth:
        type: bearer
        secretRef: agent-api-token
    
    # Log Query Configuration (via Loki)
    logs:
      lokiUrl: http://loki-gateway.observability:80
      defaultTimeRange: 1h
      maxLines: 1000
      
      # Pre-defined queries for agents
      queries:
        errors:
          query: '{level="ERROR"}'
          description: "All error logs"
        warnings:
          query: '{level="WARNING"}'
          description: "All warning logs"
        service_errors:
          query: '{app=~"$service",level="ERROR"}'
          description: "Errors for specific service"
        recent_deploys:
          query: '{app="flux-system"} |= "Applied"'
          description: "Recent deployments"
    
    # Metrics Queries (via Prometheus)
    metrics:
      prometheusUrl: http://prometheus-operated.monitoring:9090
      
      queries:
        pod_restarts:
          query: 'increase(kube_pod_container_status_restarts_total[1h]) > 0'
          description: "Pods that restarted in the last hour"
        high_cpu:
          query: 'avg(rate(container_cpu_usage_seconds_total[5m])) by (pod) > 0.8'
          description: "Pods with high CPU usage"
        high_memory:
          query: 'avg(container_memory_usage_bytes) by (pod) / avg(container_spec_memory_limit_bytes) by (pod) > 0.8'
          description: "Pods with high memory usage"
        error_rate:
          query: 'rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])'
          description: "HTTP error rate"
    
    # Alerting Webhooks
    webhooks:
      enabled: true
      endpoints:
        - name: agent-dispatcher
          url: http://agent-dispatcher.agent-monitoring:8081/webhook
          events:
            - pod_crash
            - high_error_rate
            - deployment_failed
            - certificate_expiring
    
    # Action Endpoints (for agent remediation)
    actions:
      enabled: true
      allowedActions:
        - restart_pod
        - scale_deployment
        - rollback_deployment
        - create_preview
        - delete_preview
---
# Agent API Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agent-api
  namespace: agent-monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agent-api
  template:
    metadata:
      labels:
        app: agent-api
    spec:
      serviceAccountName: agent-api
      containers:
        - name: agent-api
          image: registry.lum.tools/agent-api:latest
          ports:
            - containerPort: 8080
              name: http
          env:
            - name: LOKI_URL
              value: "http://loki-gateway.observability:80"
            - name: PROMETHEUS_URL
              value: "http://prometheus-operated.monitoring:9090"
            - name: TEMPO_URL
              value: "http://tempo.observability:3100"
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 256Mi
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 10
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /ready
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 5
          volumeMounts:
            - name: config
              mountPath: /etc/agent-monitoring
      volumes:
        - name: config
          configMap:
            name: agent-monitoring-config
---
# ServiceAccount with RBAC for agent operations
apiVersion: v1
kind: ServiceAccount
metadata:
  name: agent-api
  namespace: agent-monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: agent-api
rules:
  # Read-only access to most resources
  - apiGroups: [""]
    resources: ["pods", "services", "configmaps", "secrets", "namespaces", "events"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources: ["deployments", "replicasets", "statefulsets", "daemonsets"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["networking.k8s.io"]
    resources: ["ingresses"]
    verbs: ["get", "list", "watch"]
  
  # Write access for specific remediation actions
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["delete"]  # For restart
  - apiGroups: ["apps"]
    resources: ["deployments"]
    verbs: ["patch"]  # For scale
  - apiGroups: ["apps"]
    resources: ["deployments/rollback"]
    verbs: ["create"]
  
  # Preview environment management
  - apiGroups: [""]
    resources: ["namespaces"]
    verbs: ["create", "delete"]
    resourceNames: ["preview-*"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: agent-api
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: agent-api
subjects:
  - kind: ServiceAccount
    name: agent-api
    namespace: agent-monitoring
---
# Service for agent API
apiVersion: v1
kind: Service
metadata:
  name: agent-api
  namespace: agent-monitoring
spec:
  selector:
    app: agent-api
  ports:
    - port: 8080
      targetPort: 8080
      name: http
  type: ClusterIP
---
# Ingress for external agent access
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: agent-api
  namespace: agent-monitoring
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  ingressClassName: traefik
  tls:
    - hosts:
        - agent-api.lum.tools
      secretName: agent-api-tls
  rules:
    - host: agent-api.lum.tools
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: agent-api
                port:
                  number: 8080
---
# Grafana Alert Rules for Agent Notification
apiVersion: v1
kind: ConfigMap
metadata:
  name: agent-alert-rules
  namespace: observability
  labels:
    grafana_alert: "1"
data:
  agent-alerts.yaml: |
    apiVersion: 1
    groups:
      - orgId: 1
        name: agent-notifications
        folder: Agent Alerts
        interval: 1m
        rules:
          - uid: pod-crash-loop
            title: Pod CrashLoopBackOff
            condition: A
            data:
              - refId: A
                datasourceUid: prometheus
                model:
                  expr: kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff"} > 0
            for: 5m
            annotations:
              summary: "Pod {{ $labels.pod }} is in CrashLoopBackOff"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been crashing"
            labels:
              severity: critical
              agent_notify: "true"
          
          - uid: high-error-rate
            title: High Error Rate
            condition: A
            data:
              - refId: A
                datasourceUid: prometheus
                model:
                  expr: sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) > 0.05
            for: 5m
            annotations:
              summary: "High error rate detected"
              description: "Error rate is above 5% for the last 5 minutes"
            labels:
              severity: warning
              agent_notify: "true"
          
          - uid: deployment-failed
            title: Deployment Failed
            condition: A
            data:
              - refId: A
                datasourceUid: prometheus
                model:
                  expr: kube_deployment_status_replicas_unavailable > 0
            for: 10m
            annotations:
              summary: "Deployment {{ $labels.deployment }} has unavailable replicas"
              description: "Deployment {{ $labels.deployment }} in {{ $labels.namespace }} has {{ $value }} unavailable replicas"
            labels:
              severity: critical
              agent_notify: "true"
